{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use langchain with Azure Cognitive Search and OpenAI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents --pre --upgrade\n",
    "! pip install openai --upgrade\n",
    "! pip install python-dotenv\n",
    "! pip install tenacity --upgrade\n",
    "! pip install openai[datalib] --upgrade\n",
    "! pip install langchain --upgrade\n",
    "! pip install tiktoken --upgrade\n",
    "! pip install azure-identity --upgrade\n",
    "! pip install azure-core --pre --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "\n",
    "# Configure environment variables  \n",
    "load_dotenv(override=True)  \n",
    "# OpenAI init\n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")  \n",
    "# Form Recognizer init\n",
    "formrecognizer_key = os.getenv(\"AZURE_FORMRECOGNIZER_KEY\")\n",
    "formrecognizer_creds = AzureKeyCredential(formrecognizer_key)\n",
    "formrecognizerservice = os.getenv(\"AZURE_FORMRECOGNIZER_SERVICE\")\n",
    "# Azure search init\n",
    "searchservice = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "azure_search_endpoint = f\"https://{searchservice}.search.windows.net/\"\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
    "azure_search_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
    "search_credential = AzureKeyCredential(azure_search_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PDF parse functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import html\n",
    "\n",
    "def table_to_html(table):\n",
    "    table_html = \"<table>\"\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "def get_document_text(filename):\n",
    "    offset = 0\n",
    "    page_map = []\n",
    "    print(f\"Extracting text from '{filename}' using Azure Form Recognizer\")\n",
    "\n",
    "    form_recognizer_client = DocumentAnalysisClient(endpoint=f\"https://{formrecognizerservice}.cognitiveservices.azure.com/\", credential=formrecognizer_creds, headers={\"x-ms-useragent\": \"azure-search-chat-demo/1.0.0\"})\n",
    "    with open(filename, \"rb\") as f:\n",
    "        poller = form_recognizer_client.begin_analyze_document(\"prebuilt-layout\", document = f)\n",
    "    form_recognizer_results = poller.result()\n",
    "\n",
    "    for page_num, page in enumerate(form_recognizer_results.pages):\n",
    "        tables_on_page = [table for table in form_recognizer_results.tables if table.bounding_regions[0].page_number == page_num + 1]\n",
    "\n",
    "        # mark all positions of the table spans in the page\n",
    "        page_offset = page.spans[0].offset\n",
    "        page_length = page.spans[0].length\n",
    "        table_chars = [-1]*page_length\n",
    "        for table_id, table in enumerate(tables_on_page):\n",
    "            for span in table.spans:\n",
    "                # replace all table spans with \"table_id\" in table_chars array\n",
    "                for i in range(span.length):\n",
    "                    idx = span.offset - page_offset + i\n",
    "                    if idx >=0 and idx < page_length:\n",
    "                        table_chars[idx] = table_id\n",
    "\n",
    "        # build page text by replacing charcters in table spans with table html\n",
    "        page_text = \"\"\n",
    "        added_tables = set()\n",
    "        for idx, table_id in enumerate(table_chars):\n",
    "            if table_id == -1:\n",
    "                page_text += form_recognizer_results.content[page_offset + idx]\n",
    "            elif not table_id in added_tables:\n",
    "                page_text += table_to_html(tables_on_page[table_id])\n",
    "                added_tables.add(table_id)\n",
    "\n",
    "        page_text += \" \"\n",
    "        page_map.append((page_num, offset, page_text))\n",
    "        offset += len(page_text)\n",
    "\n",
    "    return page_map\n",
    "\n",
    "\n",
    "print(f\"https://{formrecognizerservice}.cognitiveservices.azure.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to upload cognitive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def blob_name_from_file_page(filename, page = 0):\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        return os.path.splitext(os.path.basename(filename))[0] + f\"-{page}\" + \".pdf\"\n",
    "    else:\n",
    "        return os.path.basename(filename)\n",
    "    \n",
    "def create_sections(filename, page_map):\n",
    "    for page in page_map:\n",
    "        pagenum=page[0]+1\n",
    "        id = re.sub(\"[^0-9a-zA-Z_-]\",\"_\",f\"{filename}-{pagenum}\")\n",
    "        yield {\n",
    "            \"id\": id,\n",
    "            \"content\": page[2],\n",
    "            \"source\": id,\n",
    "            \"category\": \"test01\",\n",
    "            \"sourcepage\": blob_name_from_file_page(filename, pagenum),\n",
    "            \"sourcefile\": filename\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob(\".\\data\\*\"):\n",
    "    print(f\"Processing '{filename}'\")\n",
    "    page_map = get_document_text(filename)\n",
    "    sections = create_sections(os.path.basename(filename), page_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import AzureSearch\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "openai.api_key = os.getenv(\"CHATGPT_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"CHATGPT_OPENAI_API_BASE\")  \n",
    "print(\"openai.api_base\", openai.api_base)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", deployment=\"text-embedding-ada-002\", chunk_size=1, openai_api_type=\"azure\", openai_api_base= openai.api_base, openai_api_key= openai.api_key) \n",
    "print (\"search endpoint\", azure_search_endpoint)\n",
    "embedding_function=embeddings.embed_query\n",
    "\n",
    "# Connect to Azure Cognitive Search\n",
    "acs = AzureSearch(azure_search_endpoint,\n",
    "                 azure_search_key,\n",
    "                 index_name,\n",
    "                 embedding_function=embedding_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "\n",
    "def create_documents(sections):\n",
    "    documents = []\n",
    "    for section in sections:\n",
    "        metadata = {\n",
    "            \"id\": section['id'],\n",
    "            \"category\": \"test01\",\n",
    "            \"sourcepage\": section['sourcepage'],\n",
    "            \"sourcefile\": section['sourcefile'],\n",
    "            \"source\": section['id']\n",
    "        }\n",
    "        content = section['content']\n",
    "        document = Document(metadata=metadata, page_content=content)\n",
    "        documents.append(document)\n",
    "    return documents\n",
    "\n",
    "documents = create_documents(sections)\n",
    "\n",
    "acs.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "openai.api_key = os.getenv(\"CHATGPT_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"CHATGPT_OPENAI_API_BASE\")  \n",
    "print(\"openai.api_base\", openai.api_base)\n",
    "model = AzureChatOpenAI(deployment_name=\"gpt-4\", openai_api_base= openai.api_base, openai_api_key=openai.api_key, temperature=0)\n",
    "\n",
    "retriever=acs.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "Assistant helps the company employees with their questions on company policies, roles. \n",
    "Always include the source metadata for each fact you use in the response. Use square brakets to reference the source, e.g. [role_library_pdf-10]. \n",
    "Properly format the output for human readability with new lines.\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "#chain.invoke(\"where did harrison work?\")\n",
    "result = chain.invoke(\"Responsibilities of Director of Operations?\")\n",
    "print (result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
