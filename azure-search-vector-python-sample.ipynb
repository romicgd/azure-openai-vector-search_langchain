{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use langchain with Azure Cognitive Search and OpenAI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents --pre --upgrade\n",
    "! pip install openai --upgrade\n",
    "! pip install python-dotenv\n",
    "! pip install tenacity --upgrade\n",
    "! pip install openai[datalib] --upgrade\n",
    "! pip install langchain --upgrade\n",
    "! pip install tiktoken --upgrade\n",
    "! pip install azure-identity --upgrade\n",
    "! pip install azure-core --pre --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "\n",
    "# Configure environment variables  \n",
    "load_dotenv(override=True)  \n",
    "# OpenAI init\n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")  \n",
    "# Form Recognizer init\n",
    "formrecognizer_key = os.getenv(\"AZURE_FORMRECOGNIZER_KEY\")\n",
    "formrecognizer_creds = AzureKeyCredential(formrecognizer_key)\n",
    "formrecognizerservice = os.getenv(\"AZURE_FORMRECOGNIZER_SERVICE\")\n",
    "# Azure search init\n",
    "searchservice = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "azure_search_endpoint = f\"https://{searchservice}.search.windows.net/\"\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
    "azure_search_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
    "search_credential = AzureKeyCredential(azure_search_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PDF parse functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://prsaipoc-0000-ist-0604-formrcgn1.cognitiveservices.azure.com/\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import html\n",
    "\n",
    "def table_to_html(table):\n",
    "    table_html = \"<table>\"\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "def get_document_text(filename):\n",
    "    offset = 0\n",
    "    page_map = []\n",
    "    print(f\"Extracting text from '{filename}' using Azure Form Recognizer\")\n",
    "\n",
    "    form_recognizer_client = DocumentAnalysisClient(endpoint=f\"https://{formrecognizerservice}.cognitiveservices.azure.com/\", credential=formrecognizer_creds, headers={\"x-ms-useragent\": \"azure-search-chat-demo/1.0.0\"})\n",
    "    with open(filename, \"rb\") as f:\n",
    "        poller = form_recognizer_client.begin_analyze_document(\"prebuilt-layout\", document = f)\n",
    "    form_recognizer_results = poller.result()\n",
    "\n",
    "    for page_num, page in enumerate(form_recognizer_results.pages):\n",
    "        tables_on_page = [table for table in form_recognizer_results.tables if table.bounding_regions[0].page_number == page_num + 1]\n",
    "\n",
    "        # mark all positions of the table spans in the page\n",
    "        page_offset = page.spans[0].offset\n",
    "        page_length = page.spans[0].length\n",
    "        table_chars = [-1]*page_length\n",
    "        for table_id, table in enumerate(tables_on_page):\n",
    "            for span in table.spans:\n",
    "                # replace all table spans with \"table_id\" in table_chars array\n",
    "                for i in range(span.length):\n",
    "                    idx = span.offset - page_offset + i\n",
    "                    if idx >=0 and idx < page_length:\n",
    "                        table_chars[idx] = table_id\n",
    "\n",
    "        # build page text by replacing charcters in table spans with table html\n",
    "        page_text = \"\"\n",
    "        added_tables = set()\n",
    "        for idx, table_id in enumerate(table_chars):\n",
    "            if table_id == -1:\n",
    "                page_text += form_recognizer_results.content[page_offset + idx]\n",
    "            elif not table_id in added_tables:\n",
    "                page_text += table_to_html(tables_on_page[table_id])\n",
    "                added_tables.add(table_id)\n",
    "\n",
    "        page_text += \" \"\n",
    "        page_map.append((page_num, offset, page_text))\n",
    "        offset += len(page_text)\n",
    "\n",
    "    return page_map\n",
    "\n",
    "\n",
    "print(f\"https://{formrecognizerservice}.cognitiveservices.azure.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to upload cognitive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def blob_name_from_file_page(filename, page = 0):\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        return os.path.splitext(os.path.basename(filename))[0] + f\"-{page}\" + \".pdf\"\n",
    "    else:\n",
    "        return os.path.basename(filename)\n",
    "    \n",
    "def create_sections(filename, page_map):\n",
    "    for page in page_map:\n",
    "        pagenum=page[0]+1\n",
    "        id = re.sub(\"[^0-9a-zA-Z_-]\",\"_\",f\"{filename}-{pagenum}\")\n",
    "        yield {\n",
    "            \"id\": id,\n",
    "            \"content\": page[2],\n",
    "            \"source\": id,\n",
    "            \"category\": \"test01\",\n",
    "            \"sourcepage\": blob_name_from_file_page(filename, pagenum),\n",
    "            \"sourcefile\": filename\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing '.\\data\\role_library.pdf'\n",
      "Extracting text from '.\\data\\role_library.pdf' using Azure Form Recognizer\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for filename in glob.glob(\".\\data\\*\"):\n",
    "    print(f\"Processing '{filename}'\")\n",
    "    page_map = get_document_text(filename)\n",
    "    sections = create_sections(os.path.basename(filename), page_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server:  dns2.gov.on.ca\n",
      "Address:  142.107.194.46\n",
      "\n",
      "Name:    prsaipoc-0000-ist-0604-formrcgn1.privatelink.cognitiveservices.azure.com\n",
      "Address:  10.204.12.72\n",
      "Aliases:  prsaipoc-0000-ist-0604-formrcgn1.cognitiveservices.azure.com\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Non-authoritative answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! nslookup prsaipoc-0000-ist-0604-formrcgn1.cognitiveservices.azure.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai.api_base https://ist-0604-prsaipoc-0000-openai-ce.openai.azure.com/\n",
      "search endpoint https://prsaipoc0000ist0604srch01.search.windows.net/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import AzureSearch\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "openai.api_key = os.getenv(\"CHATGPT_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"CHATGPT_OPENAI_API_BASE\")  \n",
    "print(\"openai.api_base\", openai.api_base)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", deployment=\"text-embedding-ada-002\", chunk_size=1, openai_api_type=\"azure\", openai_api_base= openai.api_base, openai_api_key= openai.api_key) \n",
    "print (\"search endpoint\", azure_search_endpoint)\n",
    "embedding_function=embeddings.embed_query\n",
    "\n",
    "# Connect to Azure Cognitive Search\n",
    "acs = AzureSearch(azure_search_endpoint,\n",
    "                 azure_search_key,\n",
    "                 index_name,\n",
    "                 embedding_function=embedding_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OGM4ZTdiNzktMTJkZC00NzAyLWJmODUtOWI2NGUzMDk4ZTE1',\n",
       " 'OWZlMGZlMGYtMDMyNy00ZGRjLWEzNGItMDEwYzkzMTVlMTMw',\n",
       " 'YzlhZWMyOTctZGQ4NS00MGVmLTg4NTctMTBmNTI1MDdiODM4',\n",
       " 'MzA4YTIzNWUtNGE3Mi00ZTQ3LTk0MzYtNzAwOTI4ODg2YmJh',\n",
       " 'YzRkODFkNjUtMjE4MC00NjZlLWE1ZWItZjg4YTY3ODYzMjEw',\n",
       " 'ZDJiNzk2Y2EtMzI3Ni00MmQ1LWI2OWYtM2VhYTk5ZTA5YThm',\n",
       " 'NGRmZTY4Y2EtZGZkMS00NGE5LTljYWItYTliYTIxN2NlNTg4',\n",
       " 'NTEzYzAxZjMtNmRjZS00MDE3LTg5YTMtOGI0NTU1MmY1NjJi',\n",
       " 'MjEzMWNiNjktZDZkMC00MDNmLWI1NTgtYjE0NzNiYjhmMDZl',\n",
       " 'YjVhZjM0YjMtZDc3MC00NWJhLThiNjMtNzc1ZTUzNmFlYTUz',\n",
       " 'NjViYTZjMmQtNmU2MS00N2M2LThkZDQtZmMwMDM0NDZhMTc1',\n",
       " 'NWVjMmUxMDEtMTY0YS00ZDA5LThhMjEtOTUzZjk0ZGZhMDJk',\n",
       " 'ZTI5OGFmNDEtOTAwZS00ZmIzLThjNTItOWJlNjUyZDNhYTZi',\n",
       " 'ZThjNWNhMDYtMzY0OC00ZDMxLTlmYzYtMWQ2ZWJhZjgyMTc4',\n",
       " 'MGVjM2NhNTEtZDA4ZC00OGYyLWFkY2UtNDM1Y2NhYTU4NDJi',\n",
       " 'Y2U3MjNlYzAtYzQyMS00YTg4LTk1ZDAtMmRjNGI3M2JmYzU5',\n",
       " 'NTVhY2JmNzItMDcyNS00MzdjLThmMjItNGRkZDFiYzEyNDcy',\n",
       " 'YzdmY2ExNjMtYmY5Ny00NjdiLTk3ZmEtMTlkYjUyNDM5NDgz',\n",
       " 'ZDU3ODNmODMtYmMxZC00N2I2LWI3NDItOTA1ZmQ2MmE4MTEx',\n",
       " 'Mzc2ZDk4YzAtMTM0Ni00NmI3LTgwYWItMjdmNGFiNjI3NGY3',\n",
       " 'MGU1YzEyYzUtOTc1MC00YTA3LWEzNjAtYzdmZjAyY2I4NTdm',\n",
       " 'NWUyYWVhYjktOWNlZi00NDFlLWJkY2YtMWY4YWI5N2M0YzA1',\n",
       " 'NDVjYTUwODUtNzA1Zi00NmVmLWIyNTYtOTBkZjM4Y2Q3MmNk',\n",
       " 'MTA3M2IyMDYtNzVhNS00MzU0LTg1YTctNzMwMmZmN2M5MzMz',\n",
       " 'M2JkN2I0MzYtY2Q3YS00N2MyLWI3NDMtYTI5YmIwZTFhMTYz',\n",
       " 'MmZmNDNiYzAtMGU2Yi00OTAzLThjYWQtN2U4ZTdhMmNhYWYy',\n",
       " 'MTRkZjk1OWQtNmI1ZC00ZDQ0LWE0NzYtMzUzMDc3ODIzNzll',\n",
       " 'YzA1ZjIxMDYtMDUwNC00Y2Y2LTk1N2YtYzVkMmRmNGJiMDJh',\n",
       " 'MzhjYmE2N2QtMzc2ZC00MDE2LTk3MTEtMjliN2JkY2Q1NjZh',\n",
       " 'NWI2NWQwYjgtYzlmYi00YWJhLTlmNmUtMjEyMWQxMGZiYzMw',\n",
       " 'NjQ0ZTg5YmYtM2RiOC00ZjIwLWI3NzEtMmU2MWNjM2MyMDBm']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.document import Document\n",
    "\n",
    "def create_documents(sections):\n",
    "    documents = []\n",
    "    for section in sections:\n",
    "        metadata = {\n",
    "            \"id\": section['id'],\n",
    "            \"category\": \"test01\",\n",
    "            \"sourcepage\": section['sourcepage'],\n",
    "            \"sourcefile\": section['sourcefile'],\n",
    "            \"source\": section['id']\n",
    "        }\n",
    "        content = section['content']\n",
    "        document = Document(metadata=metadata, page_content=content)\n",
    "        documents.append(document)\n",
    "    return documents\n",
    "\n",
    "documents = create_documents(sections)\n",
    "\n",
    "acs.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai.api_base https://ist-0604-prsaipoc-0000-openai-ce.openai.azure.com/\n",
      "Question: What are responsibilities of a Vice President of Human Resources and responsibilitie Manager of Human Resources? \n",
      "Provide responses for each in bulleted format. Specify the responsibilities and source for each fact you use in the answer separately.\n",
      "Answer: Responsibilities of a Vice President of Human Resources:\n",
      "• Develop, implement and monitor comprehensive HR strategies and initiatives\n",
      "• Foster a positive and productive work environment\n",
      "• Collaborate with other departments to ensure alignment of HR initiatives with the company’s overall strategy\n",
      "• Oversee the recruitment and onboarding process\n",
      "• Develop, implement and monitor training and development initiatives\n",
      "• Manage employee relations, including conflict resolution, disciplinary action and performance management\n",
      "• Develop and implement compensation and benefit plans\n",
      "• Track and analyze HR metrics\n",
      "• Ensure compliance with all applicable laws and regulations\n",
      "• Develop and monitor HR budgets\n",
      "• Stay up-to-date on the latest HR trends and best practices\n",
      "SOURCES: role_library_pdf-10\n",
      "\n",
      "Responsibilities of a Manager of Human Resources:\n",
      "• Develop, implement, and monitor human resources policies and procedures.\n",
      "• Oversee the recruitment and selection process, ensuring that hiring and promotion decisions are made in compliance with applicable laws and regulations.\n",
      "• Monitor employee performance, providing feedback and coaching as necessary.\n",
      "• Develop compensation and benefit strategies to attract and retain top talent.\n",
      "• Handle employee relations issues such as disciplinary actions, grievances, and performance management.\n",
      "• Ensure compliance with all applicable labor laws and regulations.\n",
      "• Develop and maintain relationships with external vendors and service providers.\n",
      "• Monitor and analyze employee engagement and satisfaction.\n",
      "• Ensure a safe and healthy work environment.\n",
      "SOURCES: role_library_pdf-27\n",
      "Source Document: role_library-10.pdf\n",
      "Source Document: role_library-21.pdf\n",
      "Source Document: role_library-15.pdf\n",
      "Source Document: role_library-27.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "Assistant helps the company employees with their questions on company policies, roles. \n",
    "Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. \n",
    "Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question. \n",
    "Always include the source metadata for each fact you use in the response. Use square brakets to reference the source, e.g. [role_library_pdf-10]. \n",
    "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\")\n",
    "openai.api_key = os.getenv(\"CHATGPT_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"CHATGPT_OPENAI_API_BASE\")  \n",
    "print(\"openai.api_base\", openai.api_base)\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4\", openai_api_base= openai.api_base, openai_api_key=openai.api_key, temperature=0)\n",
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
    "qa = ConversationalRetrievalChain(question_generator=question_generator,\n",
    "                                           retriever=acs.as_retriever(),\n",
    "                                           return_source_documents=True,\n",
    "                                           combine_docs_chain=doc_chain,                                           \n",
    "                                           verbose=False)\n",
    "\n",
    "chat_history = []\n",
    "query = \"\"\"What are responsibilities of a Vice President of Human Resources and responsibilitie Manager of Human Resources? \n",
    "Provide responses for each in bulleted format. Specify the responsibilities and source for each fact you use in the answer separately.\"\"\"\n",
    "\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "for document in result.get(\"source_documents\", []):\n",
    "    print(\"Source Document:\", document.metadata[\"sourcepage\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
